{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAgIJ26r6yQ5",
        "outputId": "993aef0e-c861-4ecc-80d8-c088fe7541a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD6ZXN-q6nBv",
        "outputId": "db5491a0-e069-4d70-c7bb-2c678d4dcf03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done-1\n",
            "done-2\n",
            "done-3\n",
            "done-4\n",
            "done-5\n",
            "done-6\n",
            "done-7\n",
            "done-8\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_json('./drive/MyDrive/NN/DF_NN.json')\n",
        "print('done-1')\n",
        "# Convert x_values and y_values from string representation to lists\n",
        "print('done-2')\n",
        "# Find the maximum sequence length\n",
        "max_len = max(data['x_values'].apply(len).max(), data['y_values'].apply(len).max())\n",
        "print('done-3')\n",
        "# Pad sequences to the same length\n",
        "data['x_values_padded'] = pad_sequences(data['x_values'], maxlen=max_len, padding='post', dtype='float32').tolist()\n",
        "data['y_values_padded'] = pad_sequences(data['y_values'], maxlen=max_len, padding='post', dtype='float32').tolist()\n",
        "print('done-4')\n",
        "# Combine x and y coordinates into a single array for each trial\n",
        "data['coordinates'] = data.apply(lambda row: np.stack((row['x_values_padded'], row['y_values_padded']), axis=1), axis=1)\n",
        "print('done-5')\n",
        "# Prepare the features and labels\n",
        "X = np.stack(data['coordinates'].values)\n",
        "y = data['status'].values\n",
        "print('done-6')\n",
        "# Encode labels to binary values (0 or 1)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "print('done-7')\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print('done-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Model"
      ],
      "metadata": {
        "id": "C6EA0MJ5_Km3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uaipKij6nBw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_len, 2)),  # Mask padding values\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0pLdEyS6nBx",
        "outputId": "16196f66-1b30-49d9-ccf6-2fe89878f074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1329/1329 [==============================] - 44s 24ms/step - loss: 0.3545 - accuracy: 0.8477 - val_loss: 0.3151 - val_accuracy: 0.8733\n",
            "Epoch 2/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.3042 - accuracy: 0.8735 - val_loss: 0.2891 - val_accuracy: 0.8806\n",
            "Epoch 3/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.2798 - accuracy: 0.8859 - val_loss: 0.2750 - val_accuracy: 0.8897\n",
            "Epoch 4/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.2598 - accuracy: 0.8946 - val_loss: 0.2592 - val_accuracy: 0.8962\n",
            "Epoch 5/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.2493 - accuracy: 0.9012 - val_loss: 0.2616 - val_accuracy: 0.8943\n",
            "Epoch 6/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.2439 - accuracy: 0.9029 - val_loss: 0.2412 - val_accuracy: 0.9052\n",
            "Epoch 7/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.2356 - accuracy: 0.9067 - val_loss: 0.2430 - val_accuracy: 0.9048\n",
            "Epoch 8/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.2317 - accuracy: 0.9090 - val_loss: 0.2365 - val_accuracy: 0.9081\n",
            "Epoch 9/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.2265 - accuracy: 0.9109 - val_loss: 0.2369 - val_accuracy: 0.9042\n",
            "Epoch 10/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.2235 - accuracy: 0.9120 - val_loss: 0.2454 - val_accuracy: 0.9031\n",
            "Epoch 11/50\n",
            "1329/1329 [==============================] - 31s 23ms/step - loss: 0.2181 - accuracy: 0.9148 - val_loss: 0.2346 - val_accuracy: 0.9053\n",
            "Epoch 12/50\n",
            "1329/1329 [==============================] - 31s 24ms/step - loss: 0.2146 - accuracy: 0.9156 - val_loss: 0.2416 - val_accuracy: 0.9029\n",
            "Epoch 13/50\n",
            "1329/1329 [==============================] - 33s 25ms/step - loss: 0.2120 - accuracy: 0.9173 - val_loss: 0.2381 - val_accuracy: 0.9049\n",
            "Epoch 14/50\n",
            "1329/1329 [==============================] - 31s 23ms/step - loss: 0.2095 - accuracy: 0.9185 - val_loss: 0.2274 - val_accuracy: 0.9085\n",
            "Epoch 15/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.2038 - accuracy: 0.9198 - val_loss: 0.2250 - val_accuracy: 0.9123\n",
            "Epoch 16/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.2031 - accuracy: 0.9222 - val_loss: 0.2439 - val_accuracy: 0.9066\n",
            "Epoch 17/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.2021 - accuracy: 0.9211 - val_loss: 0.2198 - val_accuracy: 0.9117\n",
            "Epoch 18/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.2005 - accuracy: 0.9215 - val_loss: 0.2201 - val_accuracy: 0.9170\n",
            "Epoch 19/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1969 - accuracy: 0.9219 - val_loss: 0.2173 - val_accuracy: 0.9161\n",
            "Epoch 20/50\n",
            "1329/1329 [==============================] - 32s 24ms/step - loss: 0.1957 - accuracy: 0.9241 - val_loss: 0.2180 - val_accuracy: 0.9152\n",
            "Epoch 21/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1939 - accuracy: 0.9240 - val_loss: 0.2115 - val_accuracy: 0.9182\n",
            "Epoch 22/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1931 - accuracy: 0.9244 - val_loss: 0.2256 - val_accuracy: 0.9087\n",
            "Epoch 23/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1897 - accuracy: 0.9262 - val_loss: 0.2148 - val_accuracy: 0.9164\n",
            "Epoch 24/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1878 - accuracy: 0.9276 - val_loss: 0.2134 - val_accuracy: 0.9177\n",
            "Epoch 25/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1878 - accuracy: 0.9271 - val_loss: 0.2229 - val_accuracy: 0.9127\n",
            "Epoch 26/50\n",
            "1329/1329 [==============================] - 33s 25ms/step - loss: 0.1856 - accuracy: 0.9278 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
            "Epoch 27/50\n",
            "1329/1329 [==============================] - 31s 23ms/step - loss: 0.1849 - accuracy: 0.9280 - val_loss: 0.2170 - val_accuracy: 0.9119\n",
            "Epoch 28/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1826 - accuracy: 0.9285 - val_loss: 0.2136 - val_accuracy: 0.9154\n",
            "Epoch 29/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1798 - accuracy: 0.9310 - val_loss: 0.2149 - val_accuracy: 0.9179\n",
            "Epoch 30/50\n",
            "1329/1329 [==============================] - 33s 25ms/step - loss: 0.1787 - accuracy: 0.9304 - val_loss: 0.2237 - val_accuracy: 0.9133\n",
            "Epoch 31/50\n",
            "1329/1329 [==============================] - 34s 25ms/step - loss: 0.1797 - accuracy: 0.9309 - val_loss: 0.2095 - val_accuracy: 0.9202\n",
            "Epoch 32/50\n",
            "1329/1329 [==============================] - 31s 23ms/step - loss: 0.1767 - accuracy: 0.9317 - val_loss: 0.2224 - val_accuracy: 0.9126\n",
            "Epoch 33/50\n",
            "1329/1329 [==============================] - 31s 24ms/step - loss: 0.1741 - accuracy: 0.9328 - val_loss: 0.2124 - val_accuracy: 0.9167\n",
            "Epoch 34/50\n",
            "1329/1329 [==============================] - 34s 25ms/step - loss: 0.1732 - accuracy: 0.9335 - val_loss: 0.2170 - val_accuracy: 0.9168\n",
            "Epoch 35/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1724 - accuracy: 0.9334 - val_loss: 0.2093 - val_accuracy: 0.9202\n",
            "Epoch 36/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1692 - accuracy: 0.9350 - val_loss: 0.2210 - val_accuracy: 0.9150\n",
            "Epoch 37/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1697 - accuracy: 0.9351 - val_loss: 0.2281 - val_accuracy: 0.9129\n",
            "Epoch 38/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1707 - accuracy: 0.9334 - val_loss: 0.2112 - val_accuracy: 0.9170\n",
            "Epoch 39/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1682 - accuracy: 0.9355 - val_loss: 0.2153 - val_accuracy: 0.9184\n",
            "Epoch 40/50\n",
            "1329/1329 [==============================] - 31s 23ms/step - loss: 0.1659 - accuracy: 0.9354 - val_loss: 0.2158 - val_accuracy: 0.9157\n",
            "Epoch 41/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1637 - accuracy: 0.9369 - val_loss: 0.2059 - val_accuracy: 0.9223\n",
            "Epoch 42/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1630 - accuracy: 0.9365 - val_loss: 0.2116 - val_accuracy: 0.9184\n",
            "Epoch 43/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1619 - accuracy: 0.9377 - val_loss: 0.2137 - val_accuracy: 0.9177\n",
            "Epoch 44/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1594 - accuracy: 0.9386 - val_loss: 0.2121 - val_accuracy: 0.9208\n",
            "Epoch 45/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1619 - accuracy: 0.9375 - val_loss: 0.2173 - val_accuracy: 0.9164\n",
            "Epoch 46/50\n",
            "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1575 - accuracy: 0.9387 - val_loss: 0.2155 - val_accuracy: 0.9211\n",
            "Epoch 47/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1560 - accuracy: 0.9397 - val_loss: 0.2192 - val_accuracy: 0.9206\n",
            "Epoch 48/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1563 - accuracy: 0.9399 - val_loss: 0.2212 - val_accuracy: 0.9198\n",
            "Epoch 49/50\n",
            "1329/1329 [==============================] - 30s 23ms/step - loss: 0.1588 - accuracy: 0.9392 - val_loss: 0.2168 - val_accuracy: 0.9189\n",
            "Epoch 50/50\n",
            "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1542 - accuracy: 0.9395 - val_loss: 0.2196 - val_accuracy: 0.9170\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgvJ5q296nBx",
        "outputId": "7cdd9a3c-6898-4709-b799-90d0e9573e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333/333 [==============================] - 2s 7ms/step - loss: 0.2196 - accuracy: 0.9170\n",
            "Test Accuracy: 91.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "# Load the model from the file\n",
        "model.save('./drive/MyDrive/NN/NN_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Model"
      ],
      "metadata": {
        "id": "-bPJUoFe_VdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_len, 2)),  # Mask padding values\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Define learning rate schedule\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# Compile the model with a custom learning rate schedule\n",
        "model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwlzWAGS_bZZ",
        "outputId": "35dcda48-4bf5-4d53-b8f8-15de8249e2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "665/665 [==============================] - 45s 49ms/step - loss: 0.3427 - accuracy: 0.8559 - val_loss: 0.3096 - val_accuracy: 0.8791 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "665/665 [==============================] - 27s 41ms/step - loss: 0.2800 - accuracy: 0.8858 - val_loss: 0.2874 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "665/665 [==============================] - 26s 40ms/step - loss: 0.2584 - accuracy: 0.8959 - val_loss: 0.2654 - val_accuracy: 0.8909 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "665/665 [==============================] - 26s 40ms/step - loss: 0.2468 - accuracy: 0.9021 - val_loss: 0.2368 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 0.2387 - accuracy: 0.9060 - val_loss: 0.2474 - val_accuracy: 0.9024 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.2275 - accuracy: 0.9099 - val_loss: 0.2295 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.2241 - accuracy: 0.9112 - val_loss: 0.2253 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.2181 - accuracy: 0.9140 - val_loss: 0.2323 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.2145 - accuracy: 0.9158 - val_loss: 0.2250 - val_accuracy: 0.9106 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.2115 - accuracy: 0.9166 - val_loss: 0.2161 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 0.2071 - accuracy: 0.9184 - val_loss: 0.2224 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "665/665 [==============================] - 25s 37ms/step - loss: 0.2032 - accuracy: 0.9207 - val_loss: 0.2233 - val_accuracy: 0.9157 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "665/665 [==============================] - 24s 36ms/step - loss: 0.2038 - accuracy: 0.9208 - val_loss: 0.2177 - val_accuracy: 0.9164 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "665/665 [==============================] - 33s 49ms/step - loss: 0.2021 - accuracy: 0.9211 - val_loss: 0.2135 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "665/665 [==============================] - 31s 47ms/step - loss: 0.1977 - accuracy: 0.9223 - val_loss: 0.2151 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 0.1949 - accuracy: 0.9237 - val_loss: 0.2070 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1938 - accuracy: 0.9234 - val_loss: 0.2076 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "665/665 [==============================] - 27s 40ms/step - loss: 0.1890 - accuracy: 0.9262 - val_loss: 0.2121 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.1872 - accuracy: 0.9276 - val_loss: 0.2030 - val_accuracy: 0.9211 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1866 - accuracy: 0.9271 - val_loss: 0.2102 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1836 - accuracy: 0.9281 - val_loss: 0.2078 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "665/665 [==============================] - 27s 40ms/step - loss: 0.1801 - accuracy: 0.9293 - val_loss: 0.2188 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1791 - accuracy: 0.9302 - val_loss: 0.2017 - val_accuracy: 0.9212 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1787 - accuracy: 0.9305 - val_loss: 0.2023 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1775 - accuracy: 0.9313 - val_loss: 0.2080 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1754 - accuracy: 0.9318 - val_loss: 0.2104 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1726 - accuracy: 0.9322 - val_loss: 0.2056 - val_accuracy: 0.9232 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1698 - accuracy: 0.9342 - val_loss: 0.2059 - val_accuracy: 0.9204 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1687 - accuracy: 0.9349 - val_loss: 0.2104 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 0.1682 - accuracy: 0.9349 - val_loss: 0.2080 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "665/665 [==============================] - 27s 40ms/step - loss: 0.1668 - accuracy: 0.9348 - val_loss: 0.2137 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.1653 - accuracy: 0.9357 - val_loss: 0.2089 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "665/665 [==============================] - 28s 42ms/step - loss: 0.1618 - accuracy: 0.9357 - val_loss: 0.2134 - val_accuracy: 0.9216 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "# Load the model from the file\n",
        "model.save('./drive/MyDrive/NN/NN_advanced_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRLKm7P5_gRN",
        "outputId": "64e62afc-9ddc-42c0-f4c5-17c54a42f49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333/333 [==============================] - 4s 11ms/step - loss: 0.2017 - accuracy: 0.9212\n",
            "Test Accuracy: 92.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Power Intensive Model\n"
      ],
      "metadata": {
        "id": "xjpTJzVoDFxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "# Enable mixed precision training\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# Define the model within a strategy scope if using multiple GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=(max_len, 2)),  # Mask padding values\n",
        "        LSTM(256, return_sequences=True),  # Increase units\n",
        "        Dropout(0.3),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')  # Ensure output is float32\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks with correct filepath\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "# Train the model with a larger batch size\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=256, validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "# Load the model from the file\n",
        "model.save('./drive/MyDrive/NN/NN_power_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMckSvisDM89",
        "outputId": "08383c4e-2381-4ccb-d260-c4b311a0da76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "167/167 [==============================] - 40s 117ms/step - loss: 0.3396 - accuracy: 0.8551 - val_loss: 0.2742 - val_accuracy: 0.8858 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "  2/167 [..............................] - ETA: 8s - loss: 0.2384 - accuracy: 0.9004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 14s 81ms/step - loss: 0.2671 - accuracy: 0.8917 - val_loss: 0.2686 - val_accuracy: 0.8934 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "167/167 [==============================] - 14s 85ms/step - loss: 0.2424 - accuracy: 0.9032 - val_loss: 0.2456 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "167/167 [==============================] - 15s 89ms/step - loss: 0.2322 - accuracy: 0.9075 - val_loss: 0.2319 - val_accuracy: 0.9088 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "167/167 [==============================] - 15s 93ms/step - loss: 0.2279 - accuracy: 0.9097 - val_loss: 0.2365 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "167/167 [==============================] - 15s 90ms/step - loss: 0.2177 - accuracy: 0.9149 - val_loss: 0.2200 - val_accuracy: 0.9141 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "167/167 [==============================] - 14s 84ms/step - loss: 0.2118 - accuracy: 0.9169 - val_loss: 0.2184 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "167/167 [==============================] - 13s 79ms/step - loss: 0.2066 - accuracy: 0.9191 - val_loss: 0.2239 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "167/167 [==============================] - 13s 80ms/step - loss: 0.2021 - accuracy: 0.9201 - val_loss: 0.2181 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "167/167 [==============================] - 13s 79ms/step - loss: 0.1982 - accuracy: 0.9236 - val_loss: 0.2156 - val_accuracy: 0.9151 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "167/167 [==============================] - 14s 83ms/step - loss: 0.1955 - accuracy: 0.9239 - val_loss: 0.2103 - val_accuracy: 0.9158 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "167/167 [==============================] - 14s 81ms/step - loss: 0.1918 - accuracy: 0.9251 - val_loss: 0.2058 - val_accuracy: 0.9189 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "167/167 [==============================] - 14s 84ms/step - loss: 0.1891 - accuracy: 0.9281 - val_loss: 0.2067 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "167/167 [==============================] - 14s 85ms/step - loss: 0.1848 - accuracy: 0.9279 - val_loss: 0.2060 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "167/167 [==============================] - 14s 83ms/step - loss: 0.1843 - accuracy: 0.9291 - val_loss: 0.2059 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "167/167 [==============================] - 14s 82ms/step - loss: 0.1794 - accuracy: 0.9297 - val_loss: 0.2089 - val_accuracy: 0.9181 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "167/167 [==============================] - 14s 81ms/step - loss: 0.1758 - accuracy: 0.9323 - val_loss: 0.2065 - val_accuracy: 0.9189 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "167/167 [==============================] - 14s 83ms/step - loss: 0.1559 - accuracy: 0.9405 - val_loss: 0.2009 - val_accuracy: 0.9233 - lr: 2.0000e-04\n",
            "Epoch 19/50\n",
            "167/167 [==============================] - 14s 82ms/step - loss: 0.1470 - accuracy: 0.9446 - val_loss: 0.2051 - val_accuracy: 0.9237 - lr: 2.0000e-04\n",
            "Epoch 20/50\n",
            "167/167 [==============================] - 15s 88ms/step - loss: 0.1435 - accuracy: 0.9456 - val_loss: 0.2033 - val_accuracy: 0.9236 - lr: 2.0000e-04\n",
            "Epoch 21/50\n",
            "167/167 [==============================] - 15s 88ms/step - loss: 0.1396 - accuracy: 0.9474 - val_loss: 0.2038 - val_accuracy: 0.9239 - lr: 2.0000e-04\n",
            "Epoch 22/50\n",
            "167/167 [==============================] - 15s 89ms/step - loss: 0.1375 - accuracy: 0.9483 - val_loss: 0.2059 - val_accuracy: 0.9247 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "167/167 [==============================] - 14s 84ms/step - loss: 0.1348 - accuracy: 0.9500 - val_loss: 0.2068 - val_accuracy: 0.9226 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "167/167 [==============================] - 14s 86ms/step - loss: 0.1285 - accuracy: 0.9511 - val_loss: 0.2067 - val_accuracy: 0.9250 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "167/167 [==============================] - 14s 82ms/step - loss: 0.1247 - accuracy: 0.9533 - val_loss: 0.2104 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "167/167 [==============================] - 14s 84ms/step - loss: 0.1234 - accuracy: 0.9541 - val_loss: 0.2137 - val_accuracy: 0.9247 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "167/167 [==============================] - 14s 84ms/step - loss: 0.1229 - accuracy: 0.9539 - val_loss: 0.2131 - val_accuracy: 0.9240 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "167/167 [==============================] - 15s 88ms/step - loss: 0.1212 - accuracy: 0.9557 - val_loss: 0.2137 - val_accuracy: 0.9243 - lr: 1.0000e-04\n",
            "333/333 [==============================] - 5s 15ms/step - loss: 0.2009 - accuracy: 0.9234\n",
            "Test Accuracy: 92.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## God Mode Model (does not yield to better results)"
      ],
      "metadata": {
        "id": "162I1q6yP68q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "import numpy as np\n",
        "# Enable mixed precision training\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# Define the model within a strategy scope if using multiple GPUs\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=(max_len, 2)),  # Mask padding values\n",
        "        #LSTM(1024, return_sequences=True),  # Increase units\n",
        "        #Dropout(0.4),\n",
        "        LSTM(512, return_sequences=True),  # Increase units\n",
        "        Dropout(0.4),\n",
        "        LSTM(256, return_sequences=True),\n",
        "        Dropout(0.4),\n",
        "        Bidirectional(LSTM(128)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')  # Ensure output is float32\n",
        "    ])\n",
        "\n",
        "    # Define learning rate schedule\n",
        "    lr_schedule = schedules.ExponentialDecay(\n",
        "        initial_learning_rate=1e-3,\n",
        "        decay_steps=1000,\n",
        "        decay_rate=0.9,\n",
        "        staircase=True)\n",
        "\n",
        "    # Compile the model with Adam optimizer and learning rate schedule\n",
        "    optimizer = Adam(learning_rate=lr_schedule)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks with correct filepath for model checkpoint\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "# Train the model with a larger batch size and longer epochs\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=512, validation_data=(X_test, y_test),\n",
        "                    callbacks=[reduce_lr, model_checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "# Load the model from the file\n",
        "model.save('./drive/MyDrive/NN/NN_god_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tOa-iApzP9wU",
        "outputId": "20bb8844-48f5-429e-c5f5-9218fd71fb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "84/84 [==============================] - 48s 334ms/step - loss: 0.3705 - accuracy: 0.8384 - val_loss: 0.2963 - val_accuracy: 0.8818 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 17s 205ms/step - loss: 0.2691 - accuracy: 0.8935 - val_loss: 0.3018 - val_accuracy: 0.8740 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 18s 218ms/step - loss: 0.2542 - accuracy: 0.8998 - val_loss: 0.2421 - val_accuracy: 0.9036 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.2369 - accuracy: 0.9077 - val_loss: 0.2283 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.2291 - accuracy: 0.9118 - val_loss: 0.2293 - val_accuracy: 0.9110 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 18s 220ms/step - loss: 0.2226 - accuracy: 0.9129 - val_loss: 0.2311 - val_accuracy: 0.9118 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 17s 202ms/step - loss: 0.2136 - accuracy: 0.9169 - val_loss: 0.2200 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 17s 207ms/step - loss: 0.2092 - accuracy: 0.9194 - val_loss: 0.2261 - val_accuracy: 0.9115 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 17s 203ms/step - loss: 0.2077 - accuracy: 0.9192 - val_loss: 0.2128 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.2025 - accuracy: 0.9235 - val_loss: 0.2038 - val_accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 18s 213ms/step - loss: 0.1974 - accuracy: 0.9238 - val_loss: 0.2111 - val_accuracy: 0.9182 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 19s 227ms/step - loss: 0.1956 - accuracy: 0.9252 - val_loss: 0.2085 - val_accuracy: 0.9202 - lr: 9.0000e-04\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 18s 210ms/step - loss: 0.1889 - accuracy: 0.9272 - val_loss: 0.2134 - val_accuracy: 0.9174 - lr: 9.0000e-04\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.1907 - accuracy: 0.9253 - val_loss: 0.2076 - val_accuracy: 0.9223 - lr: 9.0000e-04\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 18s 218ms/step - loss: 0.1839 - accuracy: 0.9302 - val_loss: 0.2056 - val_accuracy: 0.9233 - lr: 9.0000e-04\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 17s 203ms/step - loss: 0.1812 - accuracy: 0.9302 - val_loss: 0.2033 - val_accuracy: 0.9235 - lr: 9.0000e-04\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.1807 - accuracy: 0.9304 - val_loss: 0.2041 - val_accuracy: 0.9228 - lr: 9.0000e-04\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 19s 224ms/step - loss: 0.1749 - accuracy: 0.9316 - val_loss: 0.2203 - val_accuracy: 0.9183 - lr: 9.0000e-04\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 17s 202ms/step - loss: 0.1713 - accuracy: 0.9335 - val_loss: 0.2087 - val_accuracy: 0.9221 - lr: 9.0000e-04\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 17s 202ms/step - loss: 0.1706 - accuracy: 0.9341 - val_loss: 0.2033 - val_accuracy: 0.9208 - lr: 9.0000e-04\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 17s 204ms/step - loss: 0.1669 - accuracy: 0.9365 - val_loss: 0.2110 - val_accuracy: 0.9206 - lr: 9.0000e-04\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.1670 - accuracy: 0.9360 - val_loss: 0.2053 - val_accuracy: 0.9224 - lr: 9.0000e-04\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 17s 206ms/step - loss: 0.1612 - accuracy: 0.9381 - val_loss: 0.2081 - val_accuracy: 0.9245 - lr: 9.0000e-04\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 17s 203ms/step - loss: 0.1584 - accuracy: 0.9394 - val_loss: 0.2119 - val_accuracy: 0.9238 - lr: 8.1000e-04\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 18s 211ms/step - loss: 0.1549 - accuracy: 0.9403 - val_loss: 0.2184 - val_accuracy: 0.9186 - lr: 8.1000e-04\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 19s 221ms/step - loss: 0.1543 - accuracy: 0.9396 - val_loss: 0.2096 - val_accuracy: 0.9228 - lr: 8.1000e-04\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 17s 208ms/step - loss: 0.1524 - accuracy: 0.9418 - val_loss: 0.2075 - val_accuracy: 0.9243 - lr: 8.1000e-04\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 19s 230ms/step - loss: 0.1492 - accuracy: 0.9432 - val_loss: 0.2208 - val_accuracy: 0.9216 - lr: 8.1000e-04\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 17s 207ms/step - loss: 0.1486 - accuracy: 0.9429 - val_loss: 0.2150 - val_accuracy: 0.9221 - lr: 8.1000e-04\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.1437 - accuracy: 0.9448 - val_loss: 0.2092 - val_accuracy: 0.9238 - lr: 8.1000e-04\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 19s 229ms/step - loss: 0.1396 - accuracy: 0.9473 - val_loss: 0.2125 - val_accuracy: 0.9224 - lr: 8.1000e-04\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 17s 206ms/step - loss: 0.1368 - accuracy: 0.9488 - val_loss: 0.2211 - val_accuracy: 0.9222 - lr: 8.1000e-04\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 17s 204ms/step - loss: 0.1403 - accuracy: 0.9453 - val_loss: 0.2212 - val_accuracy: 0.9221 - lr: 8.1000e-04\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.1406 - accuracy: 0.9458 - val_loss: 0.2312 - val_accuracy: 0.9190 - lr: 8.1000e-04\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 17s 207ms/step - loss: 0.1405 - accuracy: 0.9461 - val_loss: 0.2285 - val_accuracy: 0.9216 - lr: 8.1000e-04\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 18s 219ms/step - loss: 0.1326 - accuracy: 0.9492 - val_loss: 0.2256 - val_accuracy: 0.9200 - lr: 7.2900e-04\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 17s 208ms/step - loss: 0.1224 - accuracy: 0.9523 - val_loss: 0.2469 - val_accuracy: 0.9226 - lr: 7.2900e-04\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 19s 225ms/step - loss: 0.1234 - accuracy: 0.9532 - val_loss: 0.2217 - val_accuracy: 0.9212 - lr: 7.2900e-04\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 18s 218ms/step - loss: 0.1150 - accuracy: 0.9561 - val_loss: 0.2444 - val_accuracy: 0.9191 - lr: 7.2900e-04\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 18s 217ms/step - loss: 0.1108 - accuracy: 0.9571 - val_loss: 0.2592 - val_accuracy: 0.9222 - lr: 7.2900e-04\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 19s 223ms/step - loss: 0.1086 - accuracy: 0.9588 - val_loss: 0.2603 - val_accuracy: 0.9216 - lr: 7.2900e-04\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 18s 213ms/step - loss: 0.1073 - accuracy: 0.9592 - val_loss: 0.2569 - val_accuracy: 0.9177 - lr: 7.2900e-04\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.2627 - val_accuracy: 0.9167 - lr: 7.2900e-04\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 17s 206ms/step - loss: 0.1096 - accuracy: 0.9577 - val_loss: 0.2760 - val_accuracy: 0.9197 - lr: 7.2900e-04\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.1002 - accuracy: 0.9611 - val_loss: 0.2648 - val_accuracy: 0.9226 - lr: 7.2900e-04\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.0995 - accuracy: 0.9603 - val_loss: 0.3023 - val_accuracy: 0.9164 - lr: 7.2900e-04\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 17s 209ms/step - loss: 0.1014 - accuracy: 0.9616 - val_loss: 0.2765 - val_accuracy: 0.9136 - lr: 7.2900e-04\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 18s 220ms/step - loss: 0.1084 - accuracy: 0.9592 - val_loss: 0.2685 - val_accuracy: 0.9207 - lr: 6.5610e-04\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 18s 220ms/step - loss: 0.0915 - accuracy: 0.9646 - val_loss: 0.2780 - val_accuracy: 0.9200 - lr: 6.5610e-04\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 18s 210ms/step - loss: 0.0855 - accuracy: 0.9671 - val_loss: 0.2843 - val_accuracy: 0.9121 - lr: 6.5610e-04\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 18s 219ms/step - loss: 0.0887 - accuracy: 0.9658 - val_loss: 0.2908 - val_accuracy: 0.9188 - lr: 6.5610e-04\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.0821 - accuracy: 0.9677 - val_loss: 0.3216 - val_accuracy: 0.9153 - lr: 6.5610e-04\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 17s 205ms/step - loss: 0.0865 - accuracy: 0.9661 - val_loss: 0.3178 - val_accuracy: 0.9186 - lr: 6.5610e-04\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 18s 220ms/step - loss: 0.0783 - accuracy: 0.9693 - val_loss: 0.3170 - val_accuracy: 0.9135 - lr: 6.5610e-04\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 18s 219ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.3151 - val_accuracy: 0.9182 - lr: 6.5610e-04\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 17s 209ms/step - loss: 0.0750 - accuracy: 0.9715 - val_loss: 0.3299 - val_accuracy: 0.9176 - lr: 6.5610e-04\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 18s 211ms/step - loss: 0.0668 - accuracy: 0.9729 - val_loss: 0.3485 - val_accuracy: 0.9160 - lr: 6.5610e-04\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 17s 205ms/step - loss: 0.0793 - accuracy: 0.9694 - val_loss: 0.3144 - val_accuracy: 0.9169 - lr: 6.5610e-04\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 17s 204ms/step - loss: 0.0744 - accuracy: 0.9712 - val_loss: 0.3633 - val_accuracy: 0.9135 - lr: 6.5610e-04\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.0667 - accuracy: 0.9744 - val_loss: 0.3492 - val_accuracy: 0.9136 - lr: 5.9049e-04\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 18s 211ms/step - loss: 0.0581 - accuracy: 0.9780 - val_loss: 0.3622 - val_accuracy: 0.9163 - lr: 5.9049e-04\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 19s 224ms/step - loss: 0.0528 - accuracy: 0.9802 - val_loss: 0.3927 - val_accuracy: 0.9161 - lr: 5.9049e-04\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 18s 213ms/step - loss: 0.0524 - accuracy: 0.9797 - val_loss: 0.3952 - val_accuracy: 0.9131 - lr: 5.9049e-04\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 17s 204ms/step - loss: 0.0586 - accuracy: 0.9771 - val_loss: 0.3880 - val_accuracy: 0.9163 - lr: 5.9049e-04\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 17s 202ms/step - loss: 0.0503 - accuracy: 0.9813 - val_loss: 0.4075 - val_accuracy: 0.9116 - lr: 5.9049e-04\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 18s 217ms/step - loss: 0.0506 - accuracy: 0.9813 - val_loss: 0.4047 - val_accuracy: 0.9119 - lr: 5.9049e-04\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.0500 - accuracy: 0.9807 - val_loss: 0.4175 - val_accuracy: 0.9103 - lr: 5.9049e-04\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 18s 217ms/step - loss: 0.0535 - accuracy: 0.9791 - val_loss: 0.4102 - val_accuracy: 0.9132 - lr: 5.9049e-04\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 18s 221ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.4215 - val_accuracy: 0.9141 - lr: 5.9049e-04\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.4212 - val_accuracy: 0.9149 - lr: 5.9049e-04\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.0468 - accuracy: 0.9820 - val_loss: 0.4189 - val_accuracy: 0.9121 - lr: 5.9049e-04\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 17s 208ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.4427 - val_accuracy: 0.9113 - lr: 5.3144e-04\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 17s 200ms/step - loss: 0.0412 - accuracy: 0.9838 - val_loss: 0.4612 - val_accuracy: 0.9128 - lr: 5.3144e-04\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 18s 209ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.4971 - val_accuracy: 0.9128 - lr: 5.3144e-04\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 18s 216ms/step - loss: 0.0375 - accuracy: 0.9858 - val_loss: 0.4867 - val_accuracy: 0.9116 - lr: 5.3144e-04\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 17s 205ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.4026 - val_accuracy: 0.9109 - lr: 5.3144e-04\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 18s 213ms/step - loss: 0.0342 - accuracy: 0.9872 - val_loss: 0.4726 - val_accuracy: 0.9119 - lr: 5.3144e-04\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.5056 - val_accuracy: 0.9096 - lr: 5.3144e-04\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 17s 207ms/step - loss: 0.0355 - accuracy: 0.9867 - val_loss: 0.5035 - val_accuracy: 0.9109 - lr: 5.3144e-04\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 18s 217ms/step - loss: 0.0312 - accuracy: 0.9885 - val_loss: 0.5050 - val_accuracy: 0.9130 - lr: 5.3144e-04\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 19s 223ms/step - loss: 0.0323 - accuracy: 0.9879 - val_loss: 0.5052 - val_accuracy: 0.9120 - lr: 5.3144e-04\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 18s 215ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.4928 - val_accuracy: 0.9084 - lr: 5.3144e-04\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 0.5178 - val_accuracy: 0.9048 - lr: 5.3144e-04\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.4842 - val_accuracy: 0.9063 - lr: 4.7830e-04\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 17s 206ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.5340 - val_accuracy: 0.9105 - lr: 4.7830e-04\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 18s 214ms/step - loss: 0.0276 - accuracy: 0.9893 - val_loss: 0.5384 - val_accuracy: 0.9089 - lr: 4.7830e-04\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 17s 207ms/step - loss: 0.0269 - accuracy: 0.9904 - val_loss: 0.5303 - val_accuracy: 0.9095 - lr: 4.7830e-04\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 17s 206ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.5572 - val_accuracy: 0.9072 - lr: 4.7830e-04\n",
            "Epoch 89/100\n",
            "48/84 [================>.............] - ETA: 5s - loss: 0.0284 - accuracy: 0.9893"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-197ac1ad0f5f>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Train the model with a larger batch size and longer epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m history = model.fit(X_train, y_train, epochs=100, batch_size=512, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     49\u001b[0m                     callbacks=[reduce_lr, model_checkpoint])\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}